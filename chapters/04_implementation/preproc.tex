\section{Pre-processing}
As previously mentioned, the goal of the pre-processing step is to reduce the raw dataset to a more condensed representation such that subsequent algorithms will have fewer data points to process, and thus run faster and consume less energy. The reason why it is possible to save compute power by doing this, is because the DBSCAN algorithm used for finding places does not take the time dimension into account. By simply running through the data points in temporal ordering, it is possible to group points into so called Stops, which represent a temporal, and small-scale distance clustering of raw points, which are then used in the DBSCAN algorithm to identify significant places. In addition, Moves are also computed between stops, such that movement-related features can be calculated, such as distance travelled. The original implementation of these pre-processing algorithms were implemented in Python by Jonas Busk, which used vectorized computations, which Dart does not support nearly to the same extent. The algorithms therefore had to be changed slightly, and were re-implemented using a functional programming approach wherever applicable. For certain computations a more traditional imperative approach, using for-loops, was utilized.

\subsection{Finding Stops}
Firstly the raw data points are clustered based on their time-ordering and distance from each other. By reducing the raw data points to more coarse grained stops, the will become easier for identifying significant places, which is can be done since the time-ordering of the data points tell us which points can belong together in a stop. This is done by iterating over the ordered data points and building a cluster from these data points, recalculating the cluster centroids with each added data point. This is repeated until the current data point is too far away from the cluster centroid and the cluster is then saved as a stop, and a new cluster is built from the current data point. This process is repeated until all data points have been considered, which means all data points will belong to exactly one stop, and that each stop contains at least one raw data point. The parameter for finding stops is the \verb|MOVE_DIST|, i.e. the radius of each stop-cluster. The lower the parameter value, the more clusters will be found. Each stop has an assigned place, however at this stage we have not yet identified the significant places and for that reasons we assign the null-place to each stop, and assign the place later.

\begin{minted}{python}
def find_stops(dataset):
    stops = []
    n = dataset.length
    for i = 0 to n:
        j = i + 1
        cluster = dataset[i:j]
        
        # Expand stop-cluster
        while dist(cluster.centroid, dataset[j]) <= MOVE_DIST and j < n:
            j += 1
            cluster = dataset[i:j]
        
        # Current data point data[j] is outside the cluster 
        l = Location(cluster.centroid.lat, cluster.centroid.lon)

        # Create unlabelled stop with place ID -1
        s = Stop(l, cluster.arrival.min, cluster.departure.max, -1) 
        stops.add(s)
        
        # Move beyond already-seen data points
        i = j
    return stops
\end{minted}


\subsubsection{Significant Places}
For finding the significant places the stops are clustered with the DBSCAN algorithm, which will use a density-based approach to finding clusters. The parameter \verb|PLACE_DIST| is used as the max-distance between points used by DBSCAN and the Haversine distance function. The DBSCAN algorithm will assign each stop given as input with a label, which is a non-negative number for all significant places and $-1$ for all noisy stops signifying the null-place, i.e. stops not belonging to a place. After this, each stop have now been assigned a place they belong to, and this is set explicitly such that time spent at a place can be counted later.

\begin{minted}{python}
def find_places(stops):
    places = []
    
    # Perform DBSCAN clustering on stops
    labels = DBSCAN(stops, PLACE_DIST)
    
    # Aggregate stops on their assigned label
    groups = stops.group_by(labels)
    
    for id, group in (labels, groups)
        l = Location(group.lat.median, g.lon.median)
        p = Place(id, l)
        places.add(p)
        
        # Assign the current place id to each stop in the group
        for s in group:
            s.placeId = id
    
    return places, stops
\end{minted}

\subsubsection{Moves}
The moves made by the user is found by iterating over each stop and assigning all the data points which were visiting between each pair of stops, i.e. $s_i$ and $s_{i + 1}$ to it, as well as the two stops. Through this, the distance of the point-chain can be calculated, as well as the duration of the transition-period.

\begin{minted}{python}
def find_moves(dataset, stops):
    moves = []
    
    # Find all data points between each pair of stops
    for i = 0 to stops.length
        cur = stops[i]
        next = stops[i+1]
        points = dataset.filter(cur.departure <= d.timestamp 
            and d.timestamp <= next.arrival)
        m = Move(cur, next, points)
    
    return moves
\end{minted}

\subsection{Distance Function}
Geodesic vs Haversine discussion here
For all distance measures, the Haversine distance function was used due to being far easier to compute and implement and provides the same results for shorter distances, which is the case for the processing in this context. This also saves battery life. 

