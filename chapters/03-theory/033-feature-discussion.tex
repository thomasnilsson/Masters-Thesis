\section{Feature Discussion}

\subsection{Defining Stops and Places}
When defining a \textit{Place}, several edge cases come to mind such as visiting multiple buildings on a university campus, visiting two stores right next to each other, walking around in a park, i.e. having a large dispersion of the data points. There are likely many more edge cases which exist which have not been considered, but we need to generalize when coming up with a definition. To generalize we define \textit{Stops} using a radius parameter $r_{stop}$ to group data points, and likewise a radius parameter $r_{place}$ to cluster Places. These parameters define the maximally allowed dispersion of the data points which allows us to filter out singular noisy data points. In order to find suitable values for these parameters, a small synthetic dataset was used and afterwards a real-life dataset from the author moving around in Munich for 9 days was used. No in-depth parameter search was conducted, but the algorithms produces very precise results with the following parameter values:

$$r_{stop} = 25 \text{m}, \quad r_{place} = 25 \text{m}$$

\subsection{Calculating Home Stay}
For calculating the home stay two time quantities are used: The total time stayed at home and the total time spent at all places, where the total duration spent at home can be derived from the Stops which were made at the home cluster. However for computing the total amount of time spent at any place two approaches can be used; either all Stops are considered regardless of place, or the time elapsed from 00:00 is used. Both approaches make sense in their own way, however they do not tell the same story. The first approach will not take into account if the user spends a lot of time transporting themselves between places, and these durations of transportation i.e. sitting in a bus on the way to school, could be considered as belonging to the duration of the place which one end up. I.e. if traveling from stop A to stop B, then the duration of the move from A to B should be added to the duration of place B. This approach has a lot of complexity and philosophical considerations which should be made, and therefore the second approach of simply using the time elapsed since 00:00 was used. This approach is a lot simpler but only works if the every single second is accounted for.

\subsection{Defining the Routine Index}
We define a routine as the repeating of a pattern - in this case in terms of the places visited at a certain time of the day. This includes where how much time is spent at home and when. However, most people will go on vacation during the year, which means the place where they sleep changes. In general, peoples' habits will inevitably change somewhat over time, and if one compares the routine of a certain person now to what their routine looked like a year ago, it is not unlikely to be very different. However just because someone changes their routine over time, does not mean they don't currently possess one. Therefore it was chosen to base the \textit{Routine Index} on the last 4 weeks (28 days) of data in order to base the routine overlap on more recent days. An issue which was not considered for this thesis, is the fact that the routine on weekdays differs a lot from the routine during the weekend. This is especially true for people who spent 8 or more hours at work during the weekdays and spent those 8 hours somewhere else during Saturday and Sunday since it means the \textit{Routine Index} cannot exceed $\frac{2}{3}$ due to a third of the day's total hours being spent at a different place than usual. To add to this, even weekdays may look slightly different from one another, especially for those who are part of sports clubs which meet during certain days of the week. In future work it would be interesting to investigate whether or not comparing Mondays to Mondays and vice versa for every day in the week would yield more accurate results. In addition, the \texit{Routine Index} cannot rely on a full day of data if it is to be calculated in real-time. To make the feature represent something meaningful given an incomplete day of data, it should reflect the routine of the user up until the current time of the day. This means if it is calculated at 14:00 then it should only take into consideration the data from the first 14 hours from previous days as well. Because of this, the \textit{Routine Index} may be high early in the day since people usually sleep the same place, but are open to deviating as the day progresses. This variance in real-time can be useful to an application programmer in a recommender-system setting, where a trigger based on the \textit{Routine Index} can be set, such that the user is alerted when the value falls below a certain threshold.

\subsection{Relying on Historical Data}
In order to calculate the \textit{Routine Index} we need to have access to the data from previous days. Essentially, the Routine Index can be computed from the Stops only, since a set of Stops cluster into a set of Places, after which the Hour Matrix, that is used for the \textit{Routine Index} computation, can be derived. At its core data needs to be stored on the device such that it may be retrieved in the future and there are two approaches to do this, either by saving all the Stops for today, or compute the Hour Matrix and save this instead, since it will take up less space. In a field study (described in chapter \ref{chapter:06}), the author was found to have had just around 20 stops per day which amounts to under 600 Stops for for a 4 week period. This is a manageable number of data points to cluster with DBSCAN, which would be the only bottleneck in this approach.\\

The second approach involves keeping storing the derived \text{Hour Matrix} for each day instead. However for this approach, the \textit{Places} would also need to be saved such that the coordinates of the Places found in the future could be compared (wrt. distance). This is to ensure that the columns of the different Hour Matrices refer to the same \textit{Places}. This approach has the potential to be computationally cheaper but is more complex to implement and was therefore not chosen in this iteration.